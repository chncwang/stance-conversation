[default]
train_pair_file = /var/wqs/conversation-data2/weibo_pair_train.txt
dev_pair_file = /var/wqs/conversation-data2/weibo_pair_test.txt
test_pair_file = /var/wqs/conversation-data2/weibo_pair_test.txt
post_file = /var/wqs/conversation-data2/weibo.post.txt
response_file = /var/wqs/conversation-data2/weibo.response.txt
black_list_file = ../data/black-list.txt
; pair_file = data/original.pair.txt
check_grad = false
one_response = false
learn_test = false
save_model_per_batch = false
split_unknown_words = false
; train_sample_count = 100000
device_id = 0
output_model_file_prefix = model-
; input_model_file = /home/chncwang/Resources/baseline-final/model-09-04-2020-22-45-26-epoch12
; input_model_dir = /home/chncwang/Resources/baseline-final
program_mode = training
; program_mode = metric
; program_mode = decoding
; program_mode = interacting
; program_mode = decoded_ppl
; decoded_file = /home/chncwang/Programs/baseline-5-4/decoded-words.txt
; memory_in_gb = 3.0f
; ngram_penalty_1 = 0
; ngram_penalty_2 = 0.2
; ngram_penalty_3 = 0.3
cut_length = 50
result_count_factor = 2

[hyper]
word_dim = 300
hidden_dim = 1024
batch_size = 64
beam_size = 10
dropout = 0.1
learning_rate = 3.25e-4
min_learning_rate = 1e-4
learning_rate_decay = 0.5
warm_up_iterations = 0
warm_up_learning_rate = 1e-6
optimzer = adamw
word_cutoff = 40
word_file = /var/wqs/cn_embeddings/sgns.weibo.word
word_finetune = true
l2_reg = 1e-7
